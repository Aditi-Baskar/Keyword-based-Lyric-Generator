{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwM2Gc24kNOE",
        "outputId": "50773314-eadf-413a-b14f-6d34a3c068a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "from nltk.util import everygrams\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of all the lyrics\n",
        "f = open('ts_data.json')\n",
        "data = json.load(f)\n",
        "t=0\n",
        "all_lyrics = []\n",
        "for i in data['songs']:\n",
        "  all_lyrics.append(i['lyrics'])"
      ],
      "metadata": {
        "id": "1gn3gK8wpLY6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BR50sO_-u_3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of all the sentences of the entire lyrics\n",
        "sentences = []\n",
        "for i in all_lyrics:\n",
        "  sentences.extend(i.split('\\n'))"
      ],
      "metadata": {
        "id": "qWilL2_i367H"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "vocab = set()\n",
        "for sentence in sentences:\n",
        "  tokens = word_tokenize(sentence.lower())\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  text.append(tokens)\n",
        "  vocab.update(tokens)\n",
        "vocab1 = list(vocab)"
      ],
      "metadata": {
        "id": "l92flCEX6VXM"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ngrams = (everygrams(i,max_len=6) for i in text)"
      ],
      "metadata": {
        "id": "LZkVD-N3jfnN"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = MLE(order=6)\n",
        "#train, vocab = padded_everygram_pipeline(order=4,text=text)\n",
        "lm.fit(all_ngrams,vocab1)"
      ],
      "metadata": {
        "id": "FCGhMWsm70ii"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm.generate(num_words=30,text_seed=['let','me','love','you'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYv54JCj-PBs",
        "outputId": "2ab57fa7-0539-4ab2-ebbf-e52f70bd7abc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['let',\n",
              " 'me',\n",
              " 'want',\n",
              " 'you',\n",
              " 'more',\n",
              " 'than',\n",
              " 'i',\n",
              " 'know',\n",
              " 'how',\n",
              " 'to',\n",
              " 'mention',\n",
              " 'him',\n",
              " 'was',\n",
              " 'like',\n",
              " 'wishing',\n",
              " 'you',\n",
              " 'never',\n",
              " 'found',\n",
              " 'out',\n",
              " 'that',\n",
              " 'love',\n",
              " 'could',\n",
              " 'be',\n",
              " 'that',\n",
              " 'strong',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'let',\n",
              " 'you',\n",
              " 'go']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(\"Hello ny name is yolo\\n whar ae, yiu doing's\")"
      ],
      "metadata": {
        "id": "bCo6VgLvmZZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174dc03a-616c-4d77-90b3-2bfe8b5511e0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'ny', 'name', 'is', 'yolo', 'whar', 'ae', ',', 'yiu', 'doing', \"'s\"]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp1 = \"Hello ny name is yolo\\n whar ae, yiu doing's\"\n",
        "temp1.split(' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JurMG-mEAz-K",
        "outputId": "9b45d44c-5eeb-4c5a-8620-17558f5441c7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'ny', 'name', 'is', 'yolo\\n', 'whar', 'ae,', 'yiu', \"doing's\"]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = open('trial.txt','w')\n",
        "print(all_lyrics[0][0:80])\n",
        "s = all_lyrics[0][0:80]\n",
        "f1.write(s)\n",
        "all_lyrics[0][0:80]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "vVJ0s36iCZiC",
        "outputId": "6b5ae767-7034-404e-f942-624da760ea56"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I walked through the door with you, the air was cold\n",
            "But somethin' 'bout it felt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I walked through the door with you, the air was cold\\nBut somethin' 'bout it felt\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_vocab = set()\n",
        "all_text = []\n",
        "for i in all_lyrics:\n",
        "  all_tokens = []\n",
        "  for sentence in i.split('\\n'):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    tokens.append('\\n')\n",
        "    new_vocab.update(tokens)\n",
        "    all_tokens.extend(tokens)\n",
        "  all_text.append(all_tokens)\n",
        "vocab2 = list(new_vocab)\n",
        "new_ngrams = (everygrams(i,max_len=6) for i in all_text)"
      ],
      "metadata": {
        "id": "aj1UMvPsCzbD"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm1 = MLE(order=6)\n",
        "#train, vocab = padded_everygram_pipeline(order=4,text=text)\n",
        "lm1.fit(new_ngrams,vocab2)\n",
        "pretext = ['let','me','love','you']\n",
        "generated_lyrics = lm1.generate(num_words=100,text_seed=['let','me','love','you'],random_seed=2)\n",
        "temp_string = ''\n",
        "for word in pretext:\n",
        "  temp_string += word + ' '\n",
        "for word in generated_lyrics:\n",
        "  if(word!='\\n'):\n",
        "    temp_string += word + ' '\n",
        "  else:\n",
        "    temp_string += word\n",
        "print(temp_string)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gLTaZMxGAgF",
        "outputId": "dfb37de1-cdba-4795-97aa-fb45c8780f25"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "let me love you let me want you \n",
            "You just see right through me \n",
            "But if you only knew me \n",
            "We could be a beautiful miracle unbelievable \n",
            "Instead of just invisible \n",
            "\n",
            "Oh yeah oh \n",
            "\n",
            "There a fire inside of you \n",
            "Anytime you feel danger or fear \n",
            "Then instantly \n",
            "I will appear \n",
            "\n",
            "I every woman \n",
            "It all in me yeah oh yeah \n",
            "I can read your thoughts right now \n",
            "Every one from A to Z \n",
            "\n",
            "I can cast a spell \n",
            "See but you ca tell \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = ['how','are','you','doing','this']\n",
        "random_generated = lm1.generate(num_words=100,text_seed=['how','are','you','doing','this'],random_seed=2)\n",
        "temp_string = ''\n",
        "for word in sample_text:\n",
        "  temp_string += word + ' '\n",
        "for word in random_generated:\n",
        "  if(word!='\\n'):\n",
        "    temp_string += word + ' '\n",
        "  else:\n",
        "    temp_string += word\n",
        "print(temp_string)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZNLksoCGR9K",
        "outputId": "6c9b005b-9891-4193-b078-a7afe89ec427"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how are you doing this week \n",
            "Jealousy misery \n",
            "Gon give you what you gave to me \n",
            "\n",
            "Baby baby \n",
            "\n",
            "Oh and give you what you gave to me \n",
            "\n",
            "\n",
            "A string that pulled me \n",
            "Out of all the bricks they threw at me At me \n",
            "And every day is like a battle Every day is like a battle \n",
            "But every night with us is like a dream \n",
            "Baby we the new romantics \n",
            "The best people in life are \n",
            "Singer turned gangster \n",
            "You do want to fight me \n",
            "Straight to the \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bBy57MeKXpQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}