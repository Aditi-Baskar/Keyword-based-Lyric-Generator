{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM-cPeVuVd0G",
        "outputId": "c6491787-d9c9-45a7-ffc2-457ff080fe9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import torch\n",
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "from nltk.util import everygrams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of all the lyrics\n",
        "f = open('ts_data.json')\n",
        "data = json.load(f)\n",
        "t=0\n",
        "all_lyrics = []\n",
        "for i in data['songs']:\n",
        "  all_lyrics.append(i['lyrics'])"
      ],
      "metadata": {
        "id": "F26rEgMpXtxd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for i in all_lyrics:\n",
        "  sentences.extend(i.split('\\n'))"
      ],
      "metadata": {
        "id": "2a5oDgIkXzof"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "vocab = set()\n",
        "for sentence in sentences:\n",
        "  tokens = word_tokenize(sentence.lower())\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  text.append(tokens)\n",
        "  vocab.update(tokens)\n",
        "vocab1 = list(vocab)"
      ],
      "metadata": {
        "id": "ehWzjONTX2BW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ngrams = (everygrams(i,max_len=6) for i in text)"
      ],
      "metadata": {
        "id": "dpXuLtKCX3r1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = MLE(order=6)\n",
        "#train, vocab = padded_everygram_pipeline(order=4,text=text)\n",
        "lm.fit(all_ngrams,vocab1)"
      ],
      "metadata": {
        "id": "xOYetH1AX6Ax"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = open('trial.txt','w')\n",
        "print(all_lyrics[0][0:80])\n",
        "s = all_lyrics[0][0:80]\n",
        "f1.write(s)\n",
        "all_lyrics[0][0:80]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "DGR09nBBX7zf",
        "outputId": "be02a0c4-4238-4c81-edb6-85fec883aff1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I walked through the door with you, the air was cold\n",
            "But somethin' 'bout it felt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I walked through the door with you, the air was cold\\nBut somethin' 'bout it felt\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_vocab = set()\n",
        "all_text = []\n",
        "for i in all_lyrics:\n",
        "  all_tokens = []\n",
        "  for sentence in i.split('\\n'):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    tokens.append('\\n')\n",
        "    new_vocab.update(tokens)\n",
        "    all_tokens.extend(tokens)\n",
        "  all_text.append(all_tokens)\n",
        "vocab2 = list(new_vocab)\n",
        "new_ngrams = (everygrams(i,max_len=6) for i in all_text)"
      ],
      "metadata": {
        "id": "EvU5lPvDX_zQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To train the model for a value n\n",
        "def train_model(n):\n",
        "  new_ngrams = (everygrams(i,max_len=n) for i in all_text)\n",
        "  lm1 = MLE(order=n)\n",
        "  lm1.fit(new_ngrams,vocab2)\n",
        "  return lm1"
      ],
      "metadata": {
        "id": "c2k4osPuYCIp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(6)\n",
        "# To generate lyric give a pretext and just call the function generate_lyric\n",
        "pretext = ['let','me','love','you']\n",
        "def generate_lyric(pretext):\n",
        "  generated_lyrics = model.generate(num_words=100,text_seed=pretext,random_seed=2)\n",
        "  temp_string = ''\n",
        "  for word in pretext:\n",
        "    temp_string += word + ' '\n",
        "  for word in generated_lyrics:\n",
        "    if(word!='\\n'):\n",
        "      temp_string += word + ' '\n",
        "    else:\n",
        "      temp_string += word\n",
        "  print(temp_string)\n",
        "  return temp_string\n",
        "  \n",
        "song = generate_lyric(pretext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFXFKGFnYD1p",
        "outputId": "c51d3820-6cfb-4bf5-a9e9-8737579159ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "let me love you let me want you \n",
            "You just see right through me \n",
            "But if you only knew me \n",
            "We could be a beautiful miracle unbelievable \n",
            "Instead of just invisible \n",
            "\n",
            "Oh yeah oh \n",
            "\n",
            "There a fire inside of you \n",
            "Anytime you feel danger or fear \n",
            "Then instantly \n",
            "I will appear \n",
            "\n",
            "I every woman \n",
            "It all in me yeah oh yeah \n",
            "I can read your thoughts right now \n",
            "Every one from A to Z \n",
            "\n",
            "I can cast a spell \n",
            "See but you ca tell \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'ngram1.csv'\n",
        "filename1 = 'ngram2.csv'"
      ],
      "metadata": {
        "id": "UlO1AupY5IP_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(song)\n",
        "labels = ['lyrics','label']\n",
        "pre = [['Let','me','love','you'],\n",
        "       ['Shining','in','the','moonlight'],\n",
        "       ['Cute','teddy','of','mine'],\n",
        "       ['You','broke','thy','heart'],\n",
        "       ['Fast','show','some','speed']]\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  writer.writerow(labels)\n",
        "  for i in pre:\n",
        "    song = generate_lyric(i)\n",
        "    temp = []\n",
        "    temp.append(song)\n",
        "    temp += [1]\n",
        "    writer.writerow(temp)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKev4QSJ5L1i",
        "outputId": "4b1fe34e-ca95-498c-a31a-8c2c7967b2d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "let me love you let me want you \n",
            "You just see right through me \n",
            "But if you only knew me \n",
            "We could be a beautiful miracle unbelievable \n",
            "Instead of just invisible \n",
            "\n",
            "Oh yeah oh \n",
            "\n",
            "There a fire inside of you \n",
            "Anytime you feel danger or fear \n",
            "Then instantly \n",
            "I will appear \n",
            "\n",
            "I every woman \n",
            "It all in me yeah oh yeah \n",
            "I can read your thoughts right now \n",
            "Every one from A to Z \n",
            "\n",
            "I can cast a spell \n",
            "See but you ca tell \n",
            "\n",
            "Let me love you kiss you \n",
            "Oh baby let me miss you \n",
            "Let me see your dream about dream about \n",
            "Dream about your eyes \n",
            "\n",
            "Ah ah \n",
            "Beautiful \n",
            "Do do do do do \n",
            "Watching what you say girl \n",
            "Never blow away girl \n",
            "Living in the crazy world \n",
            "I always been the same girl \n",
            "Some days will change your life \n",
            "Yeah this could be one of them \n",
            "I just living life and thinking \n",
            "I always been the same girl \n",
            "Living in the crazy world \n",
            "I always been the same \n",
            "Shining in the moonlight was falling \n",
            "You were riding backwards in a dusty window pane \n",
            "\n",
            "Angels fly in the air tonight \n",
            "Saying was it just like swimming out on the lake \n",
            "Stars collide in the air so light \n",
            "Was it just like those promises that you made On our last night \n",
            "Oh oh oh whoa whoa yeah ohEmbed \n",
            "And all the pages are just slipping through my hands \n",
            "And Im so scared of how this ends \n",
            "\n",
            "Bye bye to everything I thought was on my side \n",
            "Bye bye baby \n",
            "I want \n",
            "Cute teddy of mine \n",
            "We meet up every Tuesday night for dinner and a glass of wine \n",
            "Este been losin sleep \n",
            "Her husband actin different and it smells like infidelity \n",
            "She says That ai my Merlot on his mouth \n",
            "That ai my jewelry on our joint account \n",
            "No there ai no doubt \n",
            "Somebody got ta catch him out \n",
            "\n",
            "I think he knows \n",
            "When we get all alone \n",
            "I make myself at home \n",
            "And he want me to stay \n",
            "I think he knows \n",
            "\n",
            "I want you bless my \n",
            "I \n",
            "You broke thy heart win woahEmbed \n",
            "\n",
            "This love this love this love this love oh \n",
            "This love this love this love \n",
            "\n",
            "Your kiss my cheek I watched you leave \n",
            "Your smile my ghost I fell to my knees \n",
            "When you young you just run \n",
            "But you come back to what you need \n",
            "This love is good this love is bad \n",
            "This love is alive back from the dead oh \n",
            "These hands had to let it go free and \n",
            "This love came back to me \n",
            "I ca help but wish you took \n",
            "Fast show some speed on the column and a dent in the door \n",
            "A young girl two hands on the wheel \n",
            "I ca replace the way it made me feel \n",
            "And I would turn her sharp \n",
            "I would make it whine \n",
            "He say You ca beat the way a old wood boat rides \n",
            "Just a little lake across the Alabama line \n",
            "But I was king of the ocean \n",
            "When Daddy let me drive \n",
            "\n",
            "Soon I be grown up \n",
            "With daughters of my own \n",
            "I let them drive my old jeep \n",
            "Across \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Second dataset"
      ],
      "metadata": {
        "id": "kdlWxTtn9cBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a list of all the lyrics\n",
        "f = open('final_dataset.json')\n",
        "data = json.load(f)\n",
        "# print(data)\n",
        "# print(type(data))\n",
        "t=0\n",
        "all_lyrics = []\n",
        "for i,j in data.items():\n",
        "  new_lyrics = j['keywords'] + \" \" + j['lyrics']\n",
        "  all_lyrics.append(new_lyrics)"
      ],
      "metadata": {
        "id": "s9qJ4KX09gK4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_vocab = set()\n",
        "all_text = []\n",
        "for i in all_lyrics:\n",
        "  all_tokens = []\n",
        "  for sentence in i.split('\\n'):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    tokens.append('\\n')\n",
        "    new_vocab.update(tokens)\n",
        "    all_tokens.extend(tokens)\n",
        "  all_text.append(all_tokens)\n",
        "vocab2 = list(new_vocab)\n",
        "new_ngrams = (everygrams(i,max_len=6) for i in all_text)"
      ],
      "metadata": {
        "id": "RlmgLQH3_pdm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(n):\n",
        "  new_ngrams = (everygrams(i,max_len=n) for i in all_text)\n",
        "  lm1 = MLE(order=n)\n",
        "  lm1.fit(new_ngrams,vocab2)\n",
        "  return lm1"
      ],
      "metadata": {
        "id": "DelSinqg_uAg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(6)\n",
        "# To generate lyric give a pretext and just call the function generate_lyric\n",
        "pretext = ['let','me','love','you']\n",
        "def generate_lyric(pretext):\n",
        "  generated_lyrics = model.generate(num_words=100,text_seed=pretext,random_seed=2)\n",
        "  temp_string = ''\n",
        "  for word in pretext:\n",
        "    temp_string += word + ' '\n",
        "  for word in generated_lyrics:\n",
        "    if(word!='\\n'):\n",
        "      temp_string += word + ' '\n",
        "    else:\n",
        "      temp_string += word\n",
        "  print(temp_string)\n",
        "  return temp_string\n",
        "  \n",
        "song = generate_lyric(pretext)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlEAvczf_wcv",
        "outputId": "6c9b1e8b-46c0-4e50-99df-ea288d7882d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "let me love you let me want you \n",
            "You just see right through me \n",
            "But if you only knew me \n",
            "We could be a beautiful miracle unbelievable \n",
            "Instead of just invisible \n",
            "\n",
            "Oh yeah oh \n",
            "\n",
            "There a fire inside of you \n",
            "Anytime you feel danger or fear \n",
            "Then instantly \n",
            "I will appear \n",
            "\n",
            "I every woman \n",
            "It all in me yeah oh yeah \n",
            "I can read your thoughts right now \n",
            "Every one from A to Z \n",
            "\n",
            "I can cast a spell \n",
            "See but you ca tell \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['lyrics','label']\n",
        "pre = [['Let','me','love','you'],\n",
        "       ['Shining','in','the','moonlight'],\n",
        "       ['Cute','teddy','of','mine'],\n",
        "       ['You','broke','thy','heart'],\n",
        "       ['Fast','show','some','speed']]\n",
        "with open(filename1, 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  writer.writerow(labels)\n",
        "  for i in pre:\n",
        "    song = generate_lyric(i)\n",
        "    temp = []\n",
        "    temp.append(song)\n",
        "    temp += [1]\n",
        "    writer.writerow(temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxx8Y6h6_y3j",
        "outputId": "cac9f209-099f-4ce9-ed39-cfd4bcf328ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let me love you kiss you \n",
            "Oh baby let me miss you \n",
            "Let me see your dream about dream about \n",
            "Dream about your eyes \n",
            "\n",
            "Ah ah \n",
            "Beautiful ey \n",
            "And it would been sweet \n",
            "If it could been me \n",
            "In my defense I have none \n",
            "For never leaving well enough alone \n",
            "But it would been fun \n",
            "If you would been the one \n",
            "Ooh \n",
            "\n",
            "I have this dream my kills me for the money \n",
            "She thinks I left them in the will \n",
            "The family gathers and reads it and \n",
            "Shining in the moonlight was falling \n",
            "You were riding backwards in a dusty window pane \n",
            "\n",
            "Angels fly in the air tonight \n",
            "Saying was it just like swimming out on the lake \n",
            "Stars collide in the air so light \n",
            "Was it just like those promises that you made On our last night \n",
            "Oh oh oh whoa whoa yeah \n",
            "But aint it funny how \n",
            "It all comes out \n",
            "Isnt life sweet \n",
            "\n",
            "But I have always been a bit reckless \n",
            "And I am not your typical princess \n",
            "Im fine just a bit of \n",
            "Cute teddy of mine \n",
            "We meet up every Tuesday night for dinner and a glass of wine \n",
            "Este been losin sleep \n",
            "Her husband actin different and it smells like infidelity \n",
            "She says That ai my Merlot on his mouth \n",
            "That ai my jewelry on our joint account \n",
            "No there ai no doubt \n",
            "Somebody got ta catch him out \n",
            "\n",
            "I think he knows \n",
            "When we get all alone \n",
            "I make myself at home \n",
            "And he want me to stay \n",
            "I think he knows \n",
            "\n",
            "I want you bless my \n",
            "I \n",
            "You broke thy heart win woah \n",
            "\n",
            "That what you get when you let your heart win woah \n",
            "That what you get when you let your heart win woah \n",
            "\n",
            "I wonder \n",
            "How am I supposed to feel when you not here \n",
            "Cause I burned every bridge I ever built when you were here \n",
            "I still try holding onto silly things I never learn \n",
            "Oh why \n",
            "All the possibilities \n",
            "I sure you heard \n",
            "That what you get when you let your heart win woah \n",
            "That what you get when you let your heart \n",
            "Fast show some speed on the column and a dent in the door \n",
            "A young girl two hands on the wheel \n",
            "I ca replace the way it made me feel \n",
            "And I would turn her sharp \n",
            "I would make it whine \n",
            "He say You ca beat the way a old wood boat rides \n",
            "Just a little lake across the Alabama line \n",
            "But I was king of the ocean \n",
            "When Daddy let me drive \n",
            "\n",
            "Soon I be grown up \n",
            "With daughters of my own \n",
            "I let them drive my old jeep \n",
            "Across \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1L87kLSr-a9Y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "import pandas as pd\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n"
      ],
      "metadata": {
        "id": "Qfea1NlN-bLt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('song_lyrics.csv')\n",
        "\n",
        "X = df['lyrics']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "\n",
        "# Looking at the nature of training data\n",
        "\n",
        "print('Shape of training data: ')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Shape of test data: ')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCHkjI_6-pOh",
        "outputId": "bf51ca5c-6e73-4ccb-c343-90bfd74dc269"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: \n",
            "(439,)\n",
            "(439,)\n",
            "Shape of test data: \n",
            "(189,)\n",
            "(189,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.preprocessing import sequence\n",
        "!pip3 install keras_preprocessing\n",
        "from keras_preprocessing import sequence\n",
        "max_words = 1000\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "# Building the CNN Model\n",
        "model = Sequential()      # initilaizing the Sequential nature for CNN model\n",
        "# Adding the embedding layer which will take in maximum of 450 words as input and provide a 32 dimensional output of those words which belong in the top_words dictionary\n",
        "model.add(Embedding(1500, 32, input_length=1500))\n",
        "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "5GIBiCHJ-5-e",
        "outputId": "f17d2088-a0a9-486e-b5a8-4d5dd192ffb8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-75433e4672eb>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_preprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmax_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Building the CNN Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: \"Hey Apple Music, this is Taylor Swift\\nMidnights tells the stories of thirteen sleepless nights scattered throughout my life\\nI hope you like it and, wherever you are, you'll meet me at midnightSee T"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the data onto model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
        "# Getting score metrics from our model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "# Displays the accuracy of correct sentiment prediction over test data\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "-rZrHaPe-_mO",
        "outputId": "bb812926-302a-4612-8700-a2e19f265c33"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-66498f467045>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fitting the data onto model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Getting score metrics from our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Displays the accuracy of correct sentiment prediction over test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 24000, but received input with shape (None, 32)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=string)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGhfSVV8_Xuy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}