{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxOZqmQz4-9d",
        "outputId": "a70eca20-704a-4244-c9b0-3bf1439bf8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "\n",
        "model = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeUWQ8Rx5h_n",
        "outputId": "1202678b-d190-4868-a284-ce6ed3bc0cce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm"
      ],
      "metadata": {
        "id": "kMso9KCk-kcJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_keywords = 'self, confidence, resilience, empowerment'\n",
        "t5_keywords = 'alcoholism, habit, exhaustion'\n",
        "\n",
        "t5 = t5_keywords.split(', ')\n",
        "gold = gold_keywords.split(', ')\n",
        "\n",
        "for k1 in t5:\n",
        "  k_t5 = np.array(model[k1])\n",
        "\n",
        "  sim = 0\n",
        "  word = \"\"\n",
        "  for k2 in gold:\n",
        "    k_gold = np.array(model[k2])\n",
        "    similarity = np.dot(k_t5,k_gold)/(norm(k_t5)*norm(k_gold))\n",
        "    if similarity > sim:\n",
        "      sim = similarity\n",
        "      word = k2\n",
        "  print(k1, word, str(sim))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBn-8qFV_TJl",
        "outputId": "2935f9c7-2414-4cd2-c3e2-307bb286337c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alcoholism self 0.19218273\n",
            "habit self 0.20957986\n",
            "exhaustion resilience 0.1777477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "f = open('/content/final_dataset.json') \n",
        "unique_songs = json.load(f)\n",
        "\n",
        "total = len(unique_songs)\n",
        "\n",
        "num_train = int(total * .8)\n",
        "num_val = int(total * .1)\n",
        "num_test = total - num_train - num_val\n",
        "\n",
        "songs = []\n",
        "for title, l in unique_songs.items():\n",
        "  songs.append(l)\n",
        "\n",
        "test_songs = songs[num_train+num_val:len(songs)]"
      ],
      "metadata": {
        "id": "9QxsyLcOAxhO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_keywords = []\n",
        "for s in test_songs:\n",
        "  t = s['keywords']\n",
        "  t = t.replace('keywords: ', '')\n",
        "  t = t.replace('.', '')\n",
        "  t = t.replace(',', '')\n",
        "  t = t.replace('-', ' ')\n",
        "  gold_keywords.append(t)"
      ],
      "metadata": {
        "id": "BoPyfvk7BK4y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_keywords[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVOmS6Q2Baf2",
        "outputId": "65040626-db79-4e08-a795-682135760d76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['say love regret apology rain',\n",
              " 'falling uncertainty love resilience',\n",
              " 'love happiness gratitude',\n",
              " 'love fairytale patience perfect',\n",
              " 'love loss rain moving on',\n",
              " 'love uncertainty trust heartbreak',\n",
              " 'homesick nostalgia peacefulness contentment',\n",
              " 'support comfort optimism love dreams',\n",
              " 'self confidence empowerment resilience',\n",
              " 'guitar love curiosity history bonding']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "t5_lyrics = []\n",
        "with open('/content/t5_testing.csv', newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        t5_lyrics.append(row['T5'])"
      ],
      "metadata": {
        "id": "sYvh5NxLCFMC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_lyrics[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "VY7XZcjgetfY",
        "outputId": "1f8d9be8-d7e5-4b2c-ac15-c88a1b7e9b12"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some time, need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some space To think about all of this\" And you said, \"I need some'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/q1.txt') as f:\n",
        "    Q1 = f.readlines() #few shot prompting first question (song)\n",
        "\n",
        "with open('/content/a1.txt') as f:\n",
        "    a1 = f.readlines() #few shot prompting first answer (keywords)\n",
        "\n",
        "with open('/content/q2.txt') as f:\n",
        "    Q2 = f.readlines() ##few shot prompting second question (song)\n",
        "\n",
        "with open('/content/a2.txt') as f:\n",
        "    a2 = f.readlines() #few shot prompting second answer (keywords)\n",
        "\n",
        "q1 = \"\"\n",
        "for q in Q1:\n",
        "  q1 = q1 + q\n",
        "\n",
        "q2 = \"\"\n",
        "for q in Q2:\n",
        "  q2 = q2 + q"
      ],
      "metadata": {
        "id": "c7W-WIRmC7Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "t5_keywords = []\n",
        "ct = 0\n",
        "\n",
        "for l in t5_lyrics:\n",
        "  \n",
        "  print(ct)\n",
        "  if ct > 0 and ct % 3 == 0:\n",
        "    print(\"Pausing\")\n",
        "    time.sleep(70)\n",
        "\n",
        "  ct = ct + 1\n",
        "  \n",
        "  lyrics = \"Q: Describe the song with the following lyrics using 3 to 5 single word keywords, where the  output is only the keywords separated by commas\\n\" + \"\\n\" + l\n",
        "\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a helpful assistant who is an expert in generating the theme of a song in 3 to 5 single word keywords from it's lyrics. You must generate only the keywords.\"},\n",
        "          {\"role\": \"user\", \"content\": q1[0]},\n",
        "          {\"role\": \"assistant\", \"content\": a1[0]},\n",
        "          {\"role\": \"user\", \"content\": q2[0]},\n",
        "          {\"role\": \"assistant\", \"content\": a2[0]},\n",
        "          {\"role\": \"user\", \"content\": lyrics}\n",
        "      ]\n",
        "    )\n",
        "  t5_keywords.append(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOmzTcdVCeZE",
        "outputId": "deba04da-db3d-423d-80c9-9b4a5fd606ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "Pausing\n",
            "4\n",
            "5\n",
            "6\n",
            "Pausing\n",
            "7\n",
            "8\n",
            "9\n",
            "Pausing\n",
            "10\n",
            "11\n",
            "12\n",
            "Pausing\n",
            "13\n",
            "14\n",
            "15\n",
            "Pausing\n",
            "16\n",
            "17\n",
            "18\n",
            "Pausing\n",
            "19\n",
            "20\n",
            "21\n",
            "Pausing\n",
            "22\n",
            "23\n",
            "24\n",
            "Pausing\n",
            "25\n",
            "26\n",
            "27\n",
            "Pausing\n",
            "28\n",
            "29\n",
            "30\n",
            "Pausing\n",
            "31\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5_keywords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0MjhYhFJOdo",
        "outputId": "7c8aea21-7a2d-485a-85b1-bb9c94377fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A: space, reflection, uncertainty',\n",
              " 'A: uncertainty, fear, confusion',\n",
              " 'A: happiness, joy, positive attitude',\n",
              " 'A: Nightlife, photography, euphoria',\n",
              " 'A: pain, moving on',\n",
              " 'A: apathy, indifference',\n",
              " 'A: repetition, contemplation, introspection',\n",
              " 'A: Dislike, frustration, rejection',\n",
              " 'A: alcoholism, exhaustion, habit',\n",
              " 'A: obsession, music, love, addiction',\n",
              " 'A: introspection, solitude, routine',\n",
              " 'A: love, beauty, concealment.',\n",
              " 'A: Battle, Family, Baby, Crying',\n",
              " 'A: frustration, confusion, self-doubt',\n",
              " 'A: nostalgia, longing, persistence.',\n",
              " 'A: loneliness',\n",
              " 'A: nostalgia, romance, longing.',\n",
              " 'A: Memories, Love, Perfection',\n",
              " 'A: insecurity, confusion, passion',\n",
              " 'A: clingy, rejection, unrequited love',\n",
              " 'A: Attachment, uncertainty, confusion',\n",
              " 'A: heartbreak, loss, confusion',\n",
              " 'A: romance, desire, change, contrast',\n",
              " 'A: Heartbreak, denial, obsession',\n",
              " 'A: love, obsession, royalty, desire.',\n",
              " 'A: nostalgia, confusion, obsession.',\n",
              " 'A: surreal, whimsical, imaginative',\n",
              " 'A: aging, insomnia, fear, anxiety',\n",
              " 'longing, devotion, heartbreak, eternity',\n",
              " 'A: gratitude, music, appreciation',\n",
              " 'A: doubt, insecurity, introspection, self-doubt.',\n",
              " 'A: regret, apology, sorrow, heartbreak',\n",
              " 'A: nostalgia, longing, memories']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(t5_keywords)):\n",
        "  t5_keywords[i] = t5_keywords[i].replace('A: ', '')\n",
        "  t5_keywords[i] = t5_keywords[i].replace('.', '')\n",
        "  t5_keywords[i] = t5_keywords[i].replace(',', '')\n",
        "  t5_keywords[i] = t5_keywords[i].replace('-', ' ')\n",
        "  t5_keywords[i] = t5_keywords[i].lower()\n",
        "  t5_keywords[i] = [t5_keywords[i]]"
      ],
      "metadata": {
        "id": "QxwzTjbLJiKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_keywords[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flAKfkKNJog8",
        "outputId": "a028cc07-f0f7-4124-8b6c-b27a8a31c793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['space reflection uncertainty']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('/content/t5_testing_keywords.csv', 'w') as f:\n",
        "      \n",
        "    # using csv.writer method from CSV package\n",
        "    write = csv.writer(f)\n",
        "      \n",
        "    write.writerow(['Keywords'])\n",
        "    write.writerows(t5_keywords)"
      ],
      "metadata": {
        "id": "Db8XxZ7ZJZVY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "t5_keywords = []\n",
        "with open('/content/t5_testing_keywords.csv', newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        #print(row)\n",
        "        t5_keywords.append(row['Keywords'])\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh4Yhv5peQ3H",
        "outputId": "5e5a5388-c081-4dee-dae2-c6748f135f86"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Keywords': 'nostalgia longing memories'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t5_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyWqXgoqeceV",
        "outputId": "0ef2025f-1d25-4779-9993-97e4cf9f0286"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['space reflection uncertainty', 'uncertainty fear confusion', 'happiness joy positive attitude', 'nightlife photography euphoria', 'pain moving on', 'apathy indifference', 'repetition contemplation introspection', 'dislike frustration rejection', 'alcoholism exhaustion habit', 'obsession music love addiction', 'introspection solitude routine', 'love beauty concealment', 'battle family baby crying', 'frustration confusion self doubt', 'nostalgia longing persistence', 'loneliness', 'nostalgia romance longing', 'memories love perfection', 'insecurity confusion passion', 'clingy rejection unrequited love', 'attachment uncertainty confusion', 'heartbreak loss confusion', 'romance desire change contrast', 'heartbreak denial obsession', 'love obsession royalty desire', 'nostalgia confusion obsession', 'surreal whimsical imaginative', 'aging insomnia fear anxiety', 'longing devotion heartbreak eternity', 'gratitude music appreciation', 'doubt insecurity introspection self doubt', 'regret apology sorrow heartbreak', 'nostalgia longing memories']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gold_keywords t5_keywords\n",
        "maximum = []\n",
        "minimum = []\n",
        "average = []\n",
        "\n",
        "for i in range(len(t5_keywords)):\n",
        "  text = t5_keywords[i].split()\n",
        "  temp = []\n",
        "  for t in text:\n",
        "    k_t5 = model[t]\n",
        "    sim = 0\n",
        "    k2 = gold_keywords[i]\n",
        "    \n",
        "    text1 = k2.split()\n",
        "    for t1 in text1:\n",
        "      if t1 in model:\n",
        "        k_gold = model[t1]\n",
        "        similarity = np.dot(k_t5,k_gold)/(norm(k_t5)*norm(k_gold))\n",
        "        sim = max(sim, similarity)\n",
        "    \n",
        "    temp.append(sim)\n",
        "\n",
        "  maximum.append(max(temp))\n",
        "  minimum.append(min(temp))\n",
        "  average.append(np.average((temp)))"
      ],
      "metadata": {
        "id": "UV-p9nWvgjba"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for i in range(33):\n",
        "  results.append([maximum[i], minimum[i], average[i]])"
      ],
      "metadata": {
        "id": "Uht5GpNGMuni"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lAPxlOEgLVL",
        "outputId": "0d02a529-5c57-462e-eb9e-69056a55c7ef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.28488111, 0.10760602, 0.21589719],\n",
              " [0.9999999, 0.43752417, 0.6789901],\n",
              " [0.9999999, 0.19980243, 0.51468956],\n",
              " [0.29846963, 0.20312142, 0.23705022],\n",
              " [1.0, 0.32314435, 0.7743814],\n",
              " [0.30676672, 0.28999478, 0.29838073],\n",
              " [0.44532308, 0.22160158, 0.3629404],\n",
              " [0.4934119, 0.24763072, 0.40867925],\n",
              " [0.20957986, 0.1777477, 0.19317012],\n",
              " [1.0000001, 0.2323369, 0.55359447]]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/semantic_evaluation.csv', 'w') as f:\n",
        "      \n",
        "    # using csv.writer method from CSV package\n",
        "    write = csv.writer(f)\n",
        "      \n",
        "    write.writerow(['Maximum', 'Minimum', 'Average'])\n",
        "    write.writerows(results)"
      ],
      "metadata": {
        "id": "XwWxhpmiPQLc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_songs[16]['keywords'])\n",
        "print(test_songs[16]['lyrics'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zix7MWZus1NT",
        "outputId": "0aa06487-ef8f-4cac-8c7f-9e817310b9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nostalgia, memories, bonding\n",
            "It was painted red, the stripe was white\n",
            "It was 18 feet from bow to stern light\n",
            "Secondhand from a dealer in Atlanta\n",
            "I rode up with daddy when he went there to get her\n",
            "We put on a shine, put on a motor\n",
            "Built out of love, and made for the water\n",
            "Ran her for years, until the transom got rotten\n",
            "A piece of my childhood will never be forgotten\n",
            "\n",
            "It was just an old plywood boat\n",
            "75 Johnson and an electric choke\n",
            "A young girl, two hands on the wheel\n",
            "I can't replace the way it made me feel\n",
            "And I would turn her sharp\n",
            "I would make it whine\n",
            "He'd say, \"You can't beat the way a old wood boat rides\"\n",
            "Just a little lake across the Alabama line\n",
            "But I was king of the ocean\n",
            "When Daddy let me drive\n",
            "\n",
            "Just an old half ton short bed Ford\n",
            "My uncle bought new in '64\n",
            "Daddy got it right cause the engine was smoking\n",
            "A couple burnt valves and he had it going\n",
            "He'd let me drive her when we haul off a load\n",
            "Down a dirt strip, we'd haul trash off of Thigpen Road\n",
            "I'd sit up in the seat and stretch my feet out to the pedals\n",
            "Smiling like a hero who just received his medal\n",
            "It was just an old hand-me-down Ford\n",
            "With 3 speed on the column and a dent in the door\n",
            "A young girl, two hands on the wheel\n",
            "I can't replace the way it made me feel and\n",
            "I would press that clutch\n",
            "And I would keep it right\n",
            "He would say a little slower, girl\n",
            "You're doing just fine\n",
            "Just a dirt road with trash on each side\n",
            "But I was Mario Andretti\n",
            "When Daddy let me drive\n",
            "\n",
            "Soon I'll be grown up\n",
            "With daughters of my own\n",
            "I let them drive my old jeep\n",
            "Across the pasture at our home\n",
            "Maybe one day they'll reach back in their file\n",
            "And pull out that old memory\n",
            "And think of me and smile\n",
            "And say\n",
            "\n",
            "It was just an old worn out jeep\n",
            "Rusty old floor boards\n",
            "Hot on my feet\n",
            "A young girl, two hands on the wheel\n",
            "I can't replace the way it made me feel\n",
            "And he'd say\n",
            "Steer it left, and turn it right\n",
            "Straighten up girl now, you're doing just fine\n",
            "Just a little valley by the river where we'd ride\n",
            "But I was high on a mountain\n",
            "When Daddy let me drive\n",
            "Oh, he let me drive\n",
            "Oh, he let me drive\n",
            "It's just an old plywood boat\n",
            "With a 75 johnson\n",
            "And electric ch\n"
          ]
        }
      ]
    }
  ]
}